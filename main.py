import os
import asyncio
import logging
from crawlers.newspick_crawler import NewspickCrawler
from apis.threads_api import ThreadsAPI
from workflows.workflow import run_workflow

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)

# 2ï¸âƒ£ í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
NEWSPICK_ID = os.getenv("NEWSPICK_ID")
NEWSPICK_PW = os.getenv("NEWSPICK_PW")
ACCESS_TOKEN = os.getenv("ACCESS_TOKEN")
THREADUSER_ID = os.getenv("THREADUSER_ID")

# 1ï¸âƒ£ í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ .env ë¡œë“œ (ë¡œì»¬ìš©)
if not all(os.getenv(var) for var in ["NEWSPICK_ID", "NEWSPICK_PW", "ACCESS_TOKEN", "THREADUSER_ID"]):
    try:
        from dotenv import load_dotenv
        load_dotenv()
        logger.info("âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ (ë¡œì»¬ ì‹¤í–‰)")
    except ImportError:
        logger.warning("âš ï¸ python-dotenv ë¯¸ì„¤ì¹˜, .env íŒŒì¼ ë¡œë“œ ë¶ˆê°€")



# 3ï¸âƒ£ ê°ì²´ ìƒì„±
crawler = NewspickCrawler(user_id=NEWSPICK_ID, password=NEWSPICK_PW)
threads_api = ThreadsAPI(access_token=ACCESS_TOKEN, user_id=THREADUSER_ID)

logger.info("ğŸš€ Workflow ì‹œì‘")
try:
    asyncio.run(run_workflow(crawler, threads_api, limit=20))
    logger.info("âœ… Workflow ì™„ë£Œ")
except Exception as e:
    logger.exception(f"âŒ Workflow ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")